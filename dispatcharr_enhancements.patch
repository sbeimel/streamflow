--- a/apps/proxy/config.py
+++ b/apps/proxy/config.py
@@ -8,7 +8,7 @@ class BaseConfig:
     CHUNK_SIZE = 8192
     CLIENT_POLL_INTERVAL = 0.1
-    MAX_RETRIES = 3
+    MAX_RETRIES = 2
     RETRY_WAIT_INTERVAL = 0.5  # seconds to wait between retries
     CONNECTION_TIMEOUT = 10  # seconds to wait for initial connection
     MAX_STREAM_SWITCHES = 10  # Maximum number of stream switch attempts before giving up
@@ -16,6 +16,13 @@ class BaseConfig:
     BUFFERING_TIMEOUT = 15  # Seconds to wait for buffering before switching streams
     BUFFER_SPEED = 1 # What speed to condsider the stream buffering, 1x is normal speed, 2x is double speed, etc.
 
+    # Stream health and recovery settings
+    MAX_HEALTH_RECOVERY_ATTEMPTS = 2     # Maximum times to attempt recovery for a single stream
+    MAX_RECONNECT_ATTEMPTS = 3           # Maximum reconnects to try before switching streams
+    MIN_STABLE_TIME_BEFORE_RECONNECT = 30  # Minimum seconds a stream must be stable to try reconnect
+    FAILOVER_GRACE_PERIOD = 20           # Extra time (seconds) to allow for stream switching before disconnecting clients
+    URL_SWITCH_TIMEOUT = 8   # Max time allowed for a stream switch operation
+
     # Cache for proxy settings (class-level, shared across all instances)
     _proxy_settings_cache = None
     _proxy_settings_cache_time = 0
@@ -32,6 +39,8 @@ class BaseConfig:
             from core.models import CoreSettings
             settings = CoreSettings.get_proxy_settings()
             cls._proxy_settings_cache = settings
+            # Override MAX_RETRIES if configured
+            cls.MAX_RETRIES = settings.get("max_retries", cls.MAX_RETRIES)
             cls._proxy_settings_cache_time = now
             return settings
 
@@ -42,6 +51,8 @@ class BaseConfig:
                 "redis_chunk_ttl": 60,
                 "channel_shutdown_delay": 0,
                 "channel_init_grace_period": 5,
+                "max_retries": 2,
+                "url_switch_timeout": 8,
             }
 
         finally:
@@ -55,6 +66,16 @@ class BaseConfig:
         """Get Redis chunk TTL from database or default"""
         settings = cls.get_proxy_settings()
         return settings.get("redis_chunk_ttl", 60)
+
+    @classmethod
+    def get_max_retries(cls):
+        """Get max retries from database or default"""
+        settings = cls.get_proxy_settings()
+        return settings.get("max_retries", 2)
+
+    @classmethod
+    def get_url_switch_timeout(cls):
+        """Get URL switch timeout from database or default"""
+        settings = cls.get_proxy_settings()
+        return settings.get("url_switch_timeout", 8)
 
     @property
     def REDIS_CHUNK_TTL(self):
@@ -95,6 +116,36 @@ class TSConfig(BaseConfig):
     CLIENT_HEARTBEAT_INTERVAL = 5  # How often to send client heartbeats (seconds)
     GHOST_CLIENT_MULTIPLIER = 6.0  # How many heartbeat intervals before client considered ghost (6 would mean 36 seconds if heartbeat interval is 6)
     CLIENT_WAIT_TIMEOUT = 30  # Seconds to wait for client to connect
+
+    # Database-dependent settings with fallbacks
+    @classmethod
+    def get_channel_shutdown_delay(cls):
+        """Get channel shutdown delay from database or default"""
+        settings = cls.get_proxy_settings()
+        return settings.get("channel_shutdown_delay", 0)
+
+    @classmethod
+    def get_buffering_timeout(cls):
+        """Get buffering timeout from database or default"""
+        settings = cls.get_proxy_settings()
+        return settings.get("buffering_timeout", 15)
+
+    @classmethod
+    def get_buffering_speed(cls):
+        """Get buffering speed threshold from database or default"""
+        settings = cls.get_proxy_settings()
+        return settings.get("buffering_speed", 1.0)
+
+    @classmethod
+    def get_channel_init_grace_period(cls):
+        """Get channel init grace period from database or default"""
+        settings = cls.get_proxy_settings()
+        return settings.get("channel_init_grace_period", 5)
+
+    @classmethod
+    def get_failover_grace_period(cls):
+        """Get failover grace period from database or default"""
+        settings = cls.get_proxy_settings()
+        return settings.get("failover_grace_period", 20)
 
     # Dynamic property access for these settings
     @property
@@ -112,3 +163,3 @@ class TSConfig(BaseConfig):
     @property
     def CHANNEL_INIT_GRACE_PERIOD(self):
         return self.get_channel_init_grace_period()

--- a/apps/m3u/models.py
+++ b/apps/m3u/models.py
@@ -99,6 +99,12 @@ class M3UAccount(models.Model):
     priority = models.PositiveIntegerField(
         default=0,
         help_text="Priority for VOD provider selection (higher numbers = higher priority). Used when multiple providers offer the same content.",
     )
+    proxy = models.CharField(
+        max_length=500,
+        blank=True,
+        null=True,
+        help_text="HTTP proxy URL for FFmpeg streams (e.g., http://proxy:8080)",
+    )
 
     def __str__(self):
         return self.name

--- a/core/models.py
+++ b/core/models.py
@@ -127,7 +127,7 @@ class StreamProfile(models.Model):
         return False
 
-    def build_command(self, stream_url, user_agent):
+    def build_command(self, stream_url, user_agent, proxy=None):
         if self.is_proxy():
             return []
 
         replacements = {
             "{streamUrl}": stream_url,
             "{userAgent}": user_agent,
         }
+        
+        # Add proxy to replacements if provided
+        if proxy:
+            replacements["{proxy}"] = proxy
 
         # Split the command and iterate through each part to apply replacements
         cmd = [self.command] + [
             self._replace_in_part(part, replacements)
             for part in shlex_split(self.parameters) # use shlex to handle quoted strings
         ]
+        
+        # Add proxy parameters to ffmpeg if proxy is provided and not already in parameters
+        if proxy and self.command == "ffmpeg" and "-http_proxy" not in self.parameters:
+            # Insert proxy parameter after ffmpeg command but before input
+            # Find the position of -i (input) parameter
+            try:
+                i_index = cmd.index("-i")
+                # Insert proxy parameters before -i
+                cmd.insert(i_index, proxy)
+                cmd.insert(i_index, "-http_proxy")
+            except ValueError:
+                # If -i not found, append at the end (before input URL)
+                cmd.extend(["-http_proxy", proxy])
 
         return cmd

--- a/apps/m3u/serializers.py
+++ b/apps/m3u/serializers.py
@@ -169,6 +169,7 @@ class M3UAccountSerializer(serializers.ModelSerializer):
             "enable_vod",
             "auto_enable_new_groups_live",
             "auto_enable_new_groups_vod",
             "auto_enable_new_groups_series",
+            "proxy",
         ]
         extra_kwargs = {
             "password": {

--- a/apps/proxy/ts_proxy/stream_manager.py
+++ b/apps/proxy/ts_proxy/stream_manager.py
@@ -22,7 +22,7 @@ from .utils import detect_stream_type, get_logger
 from .redis_keys import RedisKeys
 from .constants import ChannelState, EventType, StreamType, ChannelMetadataField, TS_PACKET_SIZE
 from .config_helper import ConfigHelper
-from .url_utils import get_alternate_streams, get_stream_info_for_switch, get_stream_object
+from .url_utils import get_alternate_streams, get_stream_info_for_switch, get_stream_object, get_stream_info_for_profile

 logger = get_logger()

@@ -65,7 +65,9 @@ class StreamManager:
         # Add tracking for tried streams and current stream
         self.current_stream_id = stream_id
+        self.current_profile_id = None
+        self.tried_combinations = set()  # Track (stream_id, profile_id) combinations
         self.tried_stream_ids = set()  # Keep for backward compatibility

         # IMPROVED LOGGING: Better handle and track stream ID
         if stream_id:
@@ -85,6 +87,12 @@ class StreamManager:
                         self.current_stream_id = int(stream_id_bytes.decode('utf-8'))
                         self.tried_stream_ids.add(self.current_stream_id)
                         logger.info(f"Loaded stream ID {self.current_stream_id} from Redis for channel {buffer.channel_id}")
+                    
+                    # Try to get profile_id
+                    profile_id_bytes = buffer.redis_client.hget(metadata_key, "m3u_profile")
+                    if profile_id_bytes:
+                        self.current_profile_id = int(profile_id_bytes.decode('utf-8'))
+                        logger.info(f"Loaded profile ID {self.current_profile_id} from Redis for channel {buffer.channel_id}")
                     
                     if not stream_id_bytes:
                         logger.warning(f"No stream_id found in Redis for channel {channel_id}. "
@@ -490,7 +498,23 @@ class StreamManager:
             else:
                 stream_profile = channel.get_stream_profile()

-            # Build and start transcode command
-            self.transcode_cmd = stream_profile.build_command(self.url, self.user_agent)
+            # Get proxy from M3U account if available
+            proxy = None
+            try:
+                # Get the channel to find the M3U account
+                from apps.channels.models import Channel
+                channel_obj = Channel.objects.get(uuid=self.channel_id)
+                
+                # Get current stream and its M3U account
+                if hasattr(self, 'current_stream_id') and self.current_stream_id:
+                    from apps.channels.models import Stream
+                    stream = Stream.objects.get(id=self.current_stream_id)
+                    if hasattr(stream, 'm3u_account') and stream.m3u_account:
+                        proxy = stream.m3u_account.proxy
+                        if proxy:
+                            logger.info(f"Using proxy {proxy} for channel {self.channel_id}")
+            except Exception as e:
+                logger.debug(f"Could not get proxy for channel {self.channel_id}: {e}")
+
+            # Build and start transcode command
+            self.transcode_cmd = stream_profile.build_command(self.url, self.user_agent, proxy)
+++ b/apps/proxy/ts_proxy/stream_manager.py
@@ -22,7 +22,7 @@ from .utils import detect_stream_type, get_logger
 from .redis_keys import RedisKeys
 from .constants import ChannelState, EventType, StreamType, ChannelMetadataField, TS_PACKET_SIZE
 from .config_helper import ConfigHelper
-from .url_utils import get_alternate_streams, get_stream_info_for_switch, get_stream_object
+from .url_utils import get_alternate_streams, get_stream_info_for_switch, get_stream_object, get_stream_info_for_profile
 
 logger = get_logger()
 
@@ -65,7 +65,9 @@ class StreamManager:
         # Add tracking for tried streams and current stream
         self.current_stream_id = stream_id
+        self.current_profile_id = None
+        self.tried_combinations = set()  # Track (stream_id, profile_id) combinations
         self.tried_stream_ids = set()  # Keep for backward compatibility
 
         # IMPROVED LOGGING: Better handle and track stream ID
         if stream_id:
@@ -85,6 +87,12 @@ class StreamManager:
                         self.current_stream_id = int(stream_id_bytes.decode('utf-8'))
                         self.tried_stream_ids.add(self.current_stream_id)
                         logger.info(f"Loaded stream ID {self.current_stream_id} from Redis for channel {buffer.channel_id}")
+                    
+                    # Try to get profile_id
+                    profile_id_bytes = buffer.redis_client.hget(metadata_key, "m3u_profile")
+                    if profile_id_bytes:
+                        self.current_profile_id = int(profile_id_bytes.decode('utf-8'))
+                        logger.info(f"Loaded profile ID {self.current_profile_id} from Redis for channel {buffer.channel_id}")
                     
                     if not stream_id_bytes:
                         logger.warning(f"No stream_id found in Redis for channel {channel_id}. "
@@ -92,6 +100,8 @@ class StreamManager:
                 except Exception as e:
                     logger.warning(f"Error loading stream ID from Redis: {e}")
+            else:
+                logger.warning(f"Unable to get stream ID for channel {channel_id}. "
+                             f"Stream switching will rely on URL comparison to avoid selecting the same stream.")

@@ -1597,7 +1607,7 @@ class StreamManager:
     def _try_next_stream(self):
         """
-        Try to switch to the next available stream for this channel.
-        Will iterate through multiple alternate streams if needed to find one with a different URL.
+        Try to switch to the next available stream/profile for this channel.
+        Supports profile failover: tries other profiles of the same stream before moving to next stream.
 
         Returns:
             bool: True if successfully switched to a new stream/profile, False otherwise
         """
         try:
-            logger.info(f"Trying to find alternative stream for channel {self.channel_id}, current stream ID: {self.current_stream_id}")
+            logger.info(f"Trying to find alternative stream/profile for channel {self.channel_id}, current stream ID: {self.current_stream_id}, current profile ID: {self.current_profile_id}")
+
+            # Mark current combination as tried
+            if self.current_stream_id and self.current_profile_id:
+                self.tried_combinations.add((self.current_stream_id, self.current_profile_id))
 
-            # Get alternate streams excluding the current one
-            alternate_streams = get_alternate_streams(self.channel_id, self.current_stream_id)
-            logger.info(f"Found {len(alternate_streams)} potential alternate streams for channel {self.channel_id}")
+            # Get alternate streams/profiles excluding the current combination
+            alternate_streams = get_alternate_streams(self.channel_id, self.current_stream_id, self.current_profile_id)
+            logger.info(f"Found {len(alternate_streams)} potential alternate stream/profile combinations for channel {self.channel_id}")
 
-            # Filter out streams we've already tried
-            untried_streams = [s for s in alternate_streams if s['stream_id'] not in self.tried_stream_ids]
-            if untried_streams:
-                ids_to_try = ', '.join([str(s['stream_id']) for s in untried_streams])
-                logger.info(f"Found {len(untried_streams)} untried streams for channel {self.channel_id}: [{ids_to_try}]")
+            # Filter out combinations we've already tried
+            untried = [s for s in alternate_streams if (s['stream_id'], s['profile_id']) not in self.tried_combinations]
+            if untried:
+                entries = ', '.join([f"{s['stream_id']}:{s['profile_id']}" for s in untried])
+                logger.info(f"Found {len(untried)} untried combinations for channel {self.channel_id}: [{entries}]")
             else:
-                logger.warning(f"No untried streams available for channel {self.channel_id}, tried: {self.tried_stream_ids}")
+                logger.warning(f"No untried stream/profile combinations available for channel {self.channel_id}, tried: {self.tried_combinations}")
 
-            if not untried_streams:
-                # Check if we have streams but they've all been tried
-                if alternate_streams and len(self.tried_stream_ids) > 0:
-                    logger.warning(f"All {len(alternate_streams)} alternate streams have been tried for channel {self.channel_id}")
+            if not untried:
+                if alternate_streams and len(self.tried_combinations) > 0:
+                    logger.warning(f"All {len(alternate_streams)} alternate combinations have been tried for channel {self.channel_id}")
                 return False
 
-            # IMPROVED: Try multiple streams until we find one with a different URL
-            for next_stream in untried_streams:
-                stream_id = next_stream['stream_id']
-                profile_id = next_stream['profile_id']  # This is the M3U profile ID we need
+            # Try combinations until we find one that works
+            for next_option in untried:
+                stream_id = next_option['stream_id']
+                profile_id = next_option['profile_id']
 
-                # Add to tried streams
-                self.tried_stream_ids.add(stream_id)
+                # Add to tried combinations
+                self.tried_combinations.add((stream_id, profile_id))
 
-                # Get stream info including URL using the profile_id we already have
-                logger.info(f"Trying next stream ID {stream_id} with profile ID {profile_id} for channel {self.channel_id}")
+                # Get stream info including URL for specific profile
+                logger.info(f"Trying stream ID {stream_id} with profile ID {profile_id} for channel {self.channel_id}")
+                stream_info = get_stream_info_for_profile(self.channel_id, stream_id, profile_id)
 
                 if 'error' in stream_info or not stream_info.get('url'):
                     logger.error(f"Error getting info for stream {stream_id} for channel {self.channel_id}: {stream_info.get('error', 'No URL')}")
-                    continue  # Try next stream instead of giving up
+                    continue
 
-                # Update URL and user agent
                 new_url = stream_info['url']
                 new_user_agent = stream_info['user_agent']
                 new_transcode = stream_info['transcode']
 
-                # CRITICAL FIX: Check if the new URL is the same as current URL
-                # This can happen when current_stream_id is None and we accidentally select the same stream
+                # Check if the new URL is the same as current URL
                 if new_url == self.url:
-                    logger.warning(f"Stream ID {stream_id} generates the same URL as current stream ({new_url}). "
-                                 f"Skipping this stream and trying next alternative.")
-                    continue  # Try next stream instead of giving up
+                    logger.warning(f"Stream ID {stream_id} generates the same URL as current stream. Skipping.")
+                    continue
 
                 logger.info(f"Switching from URL {self.url} to {new_url} for channel {self.channel_id}")
 
-                # IMPORTANT: Just update the URL, don't stop the channel or release resources
                 switch_result = self.update_url(new_url, stream_id, profile_id)
                 if not switch_result:
                     logger.error(f"Failed to update URL for stream ID {stream_id} for channel {self.channel_id}")
-                    continue  # Try next stream
+                    continue
 
-                # Update stream ID tracking
+                # Update tracking
                 self.current_stream_id = stream_id
-
-                # Store the new user agent and transcode settings
+                self.current_profile_id = profile_id
                 self.user_agent = new_user_agent
                 self.transcode = new_transcode
 
-                # Update stream metadata in Redis - use the profile_id we got from get_alternate_streams
+                # Update stream metadata in Redis
                 if hasattr(self.buffer, 'redis_client') and self.buffer.redis_client:
                     metadata_key = RedisKeys.channel_metadata(self.channel_id)
                     self.buffer.redis_client.hset(metadata_key, mapping={
                         ChannelMetadataField.URL: new_url,
                         ChannelMetadataField.USER_AGENT: new_user_agent,
                         ChannelMetadataField.STREAM_PROFILE: stream_info['stream_profile'],
-                        ChannelMetadataField.M3U_PROFILE: str(profile_id),  # Use the profile_id from get_alternate_streams
+                        ChannelMetadataField.M3U_PROFILE: str(profile_id),
                         ChannelMetadataField.STREAM_ID: str(stream_id),
                         ChannelMetadataField.STREAM_SWITCH_TIME: str(time.time()),
-                        ChannelMetadataField.STREAM_SWITCH_REASON: "max_retries_exceeded"
+                        ChannelMetadataField.STREAM_SWITCH_REASON: "failover"
                     })
-
-                    # Log the switch
-                    logger.info(f"Stream metadata updated for channel {self.channel_id} to stream ID {stream_id} with M3U profile {profile_id}")
+                    logger.info(f"Stream metadata updated for channel {self.channel_id} to stream ID {stream_id} with profile {profile_id}")
 
-                logger.info(f"Successfully switched to stream ID {stream_id} with URL {new_url} for channel {self.channel_id}")
+                logger.info(f"Successfully switched to stream ID {stream_id} with profile {profile_id} for channel {self.channel_id}")
                 return True
 
-            # If we get here, we tried all streams but none worked
-            logger.error(f"Tried {len(untried_streams)} alternate streams but none were suitable for channel {self.channel_id}")
+            logger.error(f"Tried {len(untried)} alternate combinations but none were suitable for channel {self.channel_id}")
             return False
 
         except Exception as e:
             logger.error(f"Error trying next stream for channel {self.channel_id}: {e}", exc_info=True)
             return False

--- a/apps/proxy/ts_proxy/url_utils.py
+++ b/apps/proxy/ts_proxy/url_utils.py
@@ -316,12 +316,13 @@ def get_stream_info_for_switch(channel_id: str, target_stream_id: Optional[int]
         return {'error': f'Error: {str(e)}'}
 
-def get_alternate_streams(channel_id: str, current_stream_id: Optional[int] = None) -> List[dict]:
+def get_alternate_streams(channel_id: str, current_stream_id: Optional[int] = None, current_profile_id: Optional[int] = None) -> List[dict]:
     """
-    Get alternative streams for a channel when the current stream fails.
+    Get alternative streams/profiles for a channel when the current stream fails.
+    Includes profile failover: returns all available profiles for each stream.
 
     Args:
         channel_id: The UUID of the channel
         current_stream_id: The currently failing stream ID to exclude
+        current_profile_id: The currently failing profile ID to exclude
 
     Returns:
-        List[dict]: List of stream information dictionaries with stream_id and profile_id
+        List[dict]: List of stream/profile combinations with stream_id and profile_id
     """
     try:
         from core.utils import RedisClient
@@ -333,7 +334,7 @@ def get_alternate_streams(channel_id: str, current_stream_id: Optional[int] = No
             return []
 
         redis_client = RedisClient.get_client()
-        logger.debug(f"Looking for alternate streams for channel {channel_id}, current stream ID: {current_stream_id}")
+        logger.debug(f"Looking for alternate streams for channel {channel_id}, current stream ID: {current_stream_id}, current profile ID: {current_profile_id}")
 
         # Get all assigned streams for this channel using the correct ordering
         streams = channel.streams.all().order_by('channelstream__order')
@@ -349,11 +350,6 @@ def get_alternate_streams(channel_id: str, current_stream_id: Optional[int] = No
         for stream in streams:
             logger.debug(f"Checking stream ID {stream.id} ({stream.name}) for channel {channel_id}")
 
-            # Skip the current failing stream
-            if current_stream_id and stream.id == current_stream_id:
-                logger.debug(f"Skipping current stream ID {current_stream_id}")
-                continue
-
             # Find compatible profiles for this stream with connection checking
             try:
                 m3u_account = stream.m3u_account
@@ -372,7 +368,12 @@ def get_alternate_streams(channel_id: str, current_stream_id: Optional[int] = No
                 # Check profiles in order with connection availability
                 profiles = [default_profile] + [obj for obj in m3u_profiles if not obj.is_default]
 
-                selected_profile = None
                 for profile in profiles:
+                    # Skip current stream+profile combination
+                    if current_stream_id and stream.id == current_stream_id and current_profile_id and profile.id == current_profile_id:
+                        logger.debug(f"Skipping current stream/profile combination: {current_stream_id}/{current_profile_id}")
+                        continue
+
                     # Check connection availability
                     if redis_client:
                         profile_connections_key = f"profile_connections:{profile.id}"
@@ -389,19 +390,18 @@ def get_alternate_streams(channel_id: str, current_stream_id: Optional[int] = No
 
                         # Check if profile has available slots
                         if profile.max_streams == 0 or effective_connections < profile.max_streams:
-                            selected_profile = profile
-                            logger.debug(f"Found available profile {profile.id} for stream {stream.id}: {effective_connections}/{profile.max_streams} effective (current: {current_connections}, already using: {channel_using_profile})")
-                            break
+                            alternate_streams.append({
+                                'stream_id': stream.id,
+                                'profile_id': profile.id,
+                                'name': stream.name
+                            })
+                            logger.debug(f"Added stream {stream.id} with profile {profile.id}: {effective_connections}/{profile.max_streams}")
                         else:
-                            logger.debug(f"Profile {profile.id} at max connections: {effective_connections}/{profile.max_streams} (current: {current_connections}, already using: {channel_using_profile})")
+                            logger.debug(f"Profile {profile.id} at max connections: {effective_connections}/{profile.max_streams}")
                     else:
-                        # No Redis available, assume first active profile is okay
-                        selected_profile = profile
-                        break
-
-                if selected_profile:
-                    alternate_streams.append({
-                        'stream_id': stream.id,
-                        'profile_id': selected_profile.id,
-                        'name': stream.name
-                    })
-                else:
-                    logger.debug(f"No available profiles for stream ID {stream.id}")
+                        # No Redis available, add all profiles
+                        alternate_streams.append({
+                            'stream_id': stream.id,
+                            'profile_id': profile.id,
+                            'name': stream.name
+                        })
 
             except Exception as inner_e:
                 logger.error(f"Error finding profiles for stream {stream.id}: {inner_e}")
                 continue
 
         if alternate_streams:
-            stream_ids = ', '.join([str(s['stream_id']) for s in alternate_streams])
-            logger.info(f"Found {len(alternate_streams)} alternate streams with available connections for channel {channel_id}: [{stream_ids}]")
+            entries = ', '.join([f"{s['stream_id']}:{s['profile_id']}" for s in alternate_streams])
+            logger.info(f"Found {len(alternate_streams)} alternate stream/profile combinations for channel {channel_id}: [{entries}]")
         else:
             logger.warning(f"No alternate streams with available connections found for channel {channel_id}")
 
         return alternate_streams
     except Exception as e:
         logger.error(f"Error getting alternate streams for channel {channel_id}: {e}", exc_info=True)
         return []
+
+def get_stream_info_for_profile(channel_id: str, stream_id: int, m3u_profile_id: int) -> dict:
+    """
+    Build URL/User-Agent/Transcode for a fixed combination of Stream + M3U profile.
+    Return schema compatible with get_stream_info_for_switch(...).
+    """
+    try:
+        channel = get_stream_object(channel_id)
+        if isinstance(channel, Stream):
+            logger.error(f"get_stream_info_for_profile: {channel_id} refers to a Stream, not a Channel")
+            return {"error": "Invalid channel ID"}
+        
+        stream = get_object_or_404(Stream, pk=stream_id)
+        m3u_profile = get_object_or_404(M3UAccountProfile, pk=m3u_profile_id)
+        
+        m3u_account = m3u_profile.m3u_account
+        
+        # Get the user agent from the M3U account
+        user_agent = m3u_account.get_user_agent().user_agent
+        
+        # Generate URL using the specific profile's transformation
+        input_url = stream.url
+        stream_url = transform_url(input_url, m3u_profile.search_pattern, m3u_profile.replace_pattern)
+        
+        # Get transcode info from the channel's stream profile
+        stream_profile = channel.get_stream_profile()
+        transcode = not (stream_profile.is_proxy() or stream_profile is None)
+        profile_value = stream_profile.id
+        
+        return {
+            'url': stream_url,
+            'user_agent': user_agent,
+            'transcode': transcode,
+            'stream_profile': profile_value,
+            'stream_id': stream_id,
+            'm3u_profile_id': m3u_profile_id
+        }
+    except Exception as e:
+        logger.error(f"Error in get_stream_info_for_profile: {e}", exc_info=True)
+        return {'error': f'Error: {str(e)}'}

--- a/apps/output/views.py
+++ b/apps/output/views.py
@@ -17,6 +17,45 @@ import hashlib
 
 logger = logging.getLogger(__name__)
 
+def get_basic_auth_user(request):
+    """
+    Extract and validate user from HTTP Basic Authentication header.
+    
+    Returns:
+        User object if authentication successful, None otherwise
+    """
+    auth_header = request.META.get('HTTP_AUTHORIZATION', '')
+    
+    if not auth_header.startswith('Basic '):
+        return None
+    
+    try:
+        # Decode Base64 credentials
+        encoded_credentials = auth_header[6:]  # Remove 'Basic ' prefix
+        decoded_credentials = base64.b64decode(encoded_credentials).decode('utf-8')
+        username, password = decoded_credentials.split(':', 1)
+        
+        # Get user from database
+        try:
+            user = User.objects.get(username=username)
+        except User.DoesNotExist:
+            logger.warning(f"Basic Auth failed: User '{username}' not found")
+            return None
+        
+        # Check password
+        if not user.check_password(password):
+            logger.warning(f"Basic Auth failed: Invalid password for user '{username}'")
+            return None
+        
+        # Check if user is active
+        if not user.is_active:
+            logger.warning(f"Basic Auth failed: User '{username}' is inactive")
+            return None
+        
+        return user
+        
+    except (ValueError, UnicodeDecodeError) as e:
+        logger.warning(f"Basic Auth failed: Invalid credentials format - {e}")
+        return None
+
+def require_basic_auth(request):
+    """
+    Return a 401 response requesting Basic Authentication.
+    """
+    response = HttpResponse('Authentication required', status=401)
+    response['WWW-Authenticate'] = 'Basic realm="Dispatcharr"'
+    return response
+
 def get_client_identifier(request):
     """Get client information including IP, user agent, and a unique hash identifier
 
@@ -44,6 +83,13 @@ def m3u_endpoint(request, profile_name=None, user=None):
         )
         return JsonResponse({"error": "Forbidden"}, status=403)
 
+    # Require Basic Auth if no user provided
+    if user is None:
+        user = get_basic_auth_user(request)
+        if user is None:
+            return require_basic_auth(request)
+
     # Handle HEAD requests efficiently without generating content
     if request.method == "HEAD":
         logger.debug("Handling HEAD request for M3U")
@@ -51,7 +97,7 @@ def m3u_endpoint(request, profile_name=None, user=None):
         response["Content-Disposition"] = 'attachment; filename="channels.m3u"'
         return response
 
-    return generate_m3u(request, profile_name, user)
+    return generate_m3u(request, profile_name, user)
 
 def epg_endpoint(request, profile_name=None, user=None):
     logger.debug("epg_endpoint called: method=%s, profile=%s", request.method, profile_name)
@@ -67,6 +113,13 @@ def epg_endpoint(request, profile_name=None, user=None):
         )
         return JsonResponse({"error": "Forbidden"}, status=403)
 
+    # Require Basic Auth if no user provided
+    if user is None:
+        user = get_basic_auth_user(request)
+        if user is None:
+            return require_basic_auth(request)
+
     # Handle HEAD requests efficiently without generating content
     if request.method == "HEAD":
         logger.debug("Handling HEAD request for EPG")

--- a/frontend/src/components/forms/M3U.jsx
+++ b/frontend/src/components/forms/M3U.jsx
@@ -50,6 +50,7 @@ const M3U = ({
       stale_stream_days: 7,
       priority: 0,
       enable_vod: false,
+      proxy: '',
     },
 
     validate: {
@@ -78,6 +79,7 @@ const M3U = ({
             : 0,
         enable_vod: m3uAccount.enable_vod || false,
+        proxy: m3uAccount.proxy || '',
       });
 
       if (m3uAccount.account_type == 'XC') {
@@ -158,6 +160,15 @@ const M3U = ({
                 key={form.key('server_url')}
               />
 
+              <TextInput
+                style={{ width: '100%' }}
+                id="proxy"
+                name="proxy"
+                label="HTTP Proxy"
+                placeholder="http://proxy:8080"
+                description="HTTP proxy URL for FFmpeg streams (optional)"
+                {...form.getInputProps('proxy')}
+                key={form.key('proxy')}
+              />
+
               <Select
                 id="account_type"
                 name="account_type"

--- a/frontend/src/constants.js
+++ b/frontend/src/constants.js
@@ -120,6 +120,18 @@ export const PROXY_SETTINGS_OPTIONS = {
     label: 'Channel Init Grace Period (seconds)',
     description: 'Grace period before initializing channels',
   },
+  max_retries: {
+    label: 'Max Retries',
+    description: 'Maximum number of retry attempts before switching streams',
+  },
+  url_switch_timeout: {
+    label: 'URL Switch Timeout (seconds)',
+    description: 'Maximum time allowed for stream switching operations',
+  },
+  failover_grace_period: {
+    label: 'Failover Grace Period (seconds)',
+    description: 'Extra time to allow for stream switching before disconnecting clients',
+  },
 };
 
 export const STREAM_SETTINGS_OPTIONS = {

--- a/frontend/src/components/forms/settings/ProxySettingsForm.jsx
+++ b/frontend/src/components/forms/settings/ProxySettingsForm.jsx
@@ -25,6 +25,9 @@ const ProxySettingsOptions = React.memo(({ proxySettingsForm }) => {
       'redis_chunk_ttl',
       'channel_shutdown_delay',
       'channel_init_grace_period',
+      'max_retries',
+      'url_switch_timeout',
+      'failover_grace_period',
     ].includes(key);
   };
   const isFloatField = (key) => {
@@ -37,7 +40,11 @@ const ProxySettingsOptions = React.memo(({ proxySettingsForm }) => {
         ? 3600
         : key === 'channel_shutdown_delay'
           ? 300
-          : 60;
+          : key === 'max_retries'
+            ? 10
+            : key === 'url_switch_timeout'
+              ? 60
+              : 60;
   };
   return (
     <>
@@ -16,5 +19,8 @@ export const getProxySettingsFormInitialValues = (settings) => {
     redis_chunk_ttl: settings?.redis_chunk_ttl ?? defaults.redis_chunk_ttl,
     channel_shutdown_delay: settings?.channel_shutdown_delay ?? defaults.channel_shutdown_delay,
     channel_init_grace_period: settings?.channel_init_grace_period ?? defaults.channel_init_grace_period,
+    max_retries: settings?.max_retries ?? defaults.max_retries,
+    url_switch_timeout: settings?.url_switch_timeout ?? defaults.url_switch_timeout,
+    failover_grace_period: settings?.failover_grace_period ?? defaults.failover_grace_period,
   };
 };

--- a/frontend/src/components/forms/settings/ProxySettingsForm.jsx
+++ b/frontend/src/components/forms/settings/ProxySettingsForm.jsx
@@ -25,6 +25,9 @@ const ProxySettingsOptions = React.memo(({ proxySettingsForm }) => {
       'redis_chunk_ttl',
       'channel_shutdown_delay',
       'channel_init_grace_period',
+      'max_retries',
+      'url_switch_timeout',
+      'failover_grace_period',
     ].includes(key);
   };
   const isFloatField = (key) => {
@@ -37,7 +40,11 @@ const ProxySettingsOptions = React.memo(({ proxySettingsForm }) => {
         ? 3600
         : key === 'channel_shutdown_delay'
           ? 300
-          : 60;
+          : key === 'max_retries'
+            ? 10
+            : key === 'url_switch_timeout'
+              ? 60
+              : 60;
   };
   return (
     <>

--- /dev/null
+++ b/apps/m3u/migrations/0019_m3uaccount_proxy.py
@@ -0,0 +1,18 @@
+# Generated by Django 5.2.4 on 2025-01-07 12:00
+
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+
+    dependencies = [
+        ('m3u', '0018_add_profile_custom_properties'),
+    ]
+
+    operations = [
+        migrations.AddField(
+            model_name='m3uaccount',
+            name='proxy',
+            field=models.CharField(blank=True, help_text='HTTP proxy URL for FFmpeg streams (e.g., http://proxy:8080)', max_length=500, null=True),
+        ),
+    ]

--- a/apps/proxy/ts_proxy/config_helper.py
+++ b/apps/proxy/ts_proxy/config_helper.py
@@ -84,7 +84,8 @@ class ConfigHelper:
     @staticmethod
     def failover_grace_period():
         """Get extra time (in seconds) to allow for stream switching before disconnecting clients"""
-        return ConfigHelper.get('FAILOVER_GRACE_PERIOD', 20)  # Default to 20 seconds
+        from apps.proxy.config import TSConfig
+        return TSConfig.get_failover_grace_period()

--- a/frontend/src/utils/forms/settings/ProxySettingsFormUtils.js
+++ b/frontend/src/utils/forms/settings/ProxySettingsFormUtils.js
@@ -16,5 +16,8 @@ export const getProxySettingDefaults = () => {
     redis_chunk_ttl: 60,
     channel_shutdown_delay: 0,
     channel_init_grace_period: 5,
+    max_retries: 2,
+    url_switch_timeout: 8,
+    failover_grace_period: 20,
   };
 };

# ===============================================
# DISPATCHARR ENHANCEMENTS PATCH v2.1
# ===============================================
# 
# CHANGELOG v2.1:
# - Added proxy field to M3UAccount model (apps/m3u/models.py)
# - This was missing in v2.0 and caused migration issues
# - Fixed: Model field is now included in the patch
#
# INTELLIGENT AUTO-APPLICATION SYSTEM
# This patch uses pattern matching to automatically find and modify
# the correct locations in any Dispatcharr version.
#
# SEARCH PATTERNS FOR AUTO-DETECTION:
# ====================================
#
# 1. PROFILE FAILOVER (stream_manager.py + url_utils.py):
#    FIND: "def _try_next_stream(self):"
#    FIND: "self.current_stream_id = stream_id"
#    FIND: "self.tried_stream_ids = set()"
#    ADD:  "self.tried_combinations = set()"
#    ADD:  "self.current_profile_id = None"
#    FIND: "from .url_utils import get_alternate_streams, get_stream_info_for_switch, get_stream_object"
#    ADD:  ", get_stream_info_for_profile"
#    FIND: "get_stream_info_for_switch(self.channel_id, stream_id)"
#    REPLACE: "get_stream_info_for_profile(self.channel_id, stream_id, profile_id)"
#
# 2. PROFILE FAILOVER (url_utils.py):
#    FIND: "def get_alternate_streams(channel_id: str, current_stream_id:"
#    MODIFY: Add current_profile_id parameter
#    FIND: "if current_stream_id and stream.id == current_stream_id:"
#    MODIFY: Add profile_id exclusion logic
#    ADD: "def get_stream_info_for_profile(channel_id, stream_id, profile_id)" function
#    PURPOSE: Generate URL for specific profile (vs automatic profile selection)
#
# 3. BASIC AUTH (output/views.py):
#    FIND: "def m3u_endpoint(request, profile_name=None, user=None):"
#    FIND: "def epg_endpoint(request, profile_name=None, user=None):"
#    ADD BEFORE: get_basic_auth_user() and require_basic_auth() functions
#    ADD AFTER user check: Basic auth fallback logic
#
# 4. PROXY FIELD (m3u/models.py):
#    FIND: "class M3UAccount(models.Model):"
#    FIND: "priority = models.IntegerField("
#    ADD AFTER: proxy = models.CharField(max_length=500, blank=True, null=True)
#
# 5. PROXY SERIALIZER (m3u/serializers.py):
#    FIND: "class M3UAccountSerializer(serializers.ModelSerializer):"
#    FIND: fields = [
#    FIND: "auto_enable_new_groups_series",
#    ADD AFTER: "proxy",
#
# 6. PROXY FRONTEND (frontend/src/components/forms/M3U.jsx):
#    FIND: "enable_vod: false,"
#    ADD AFTER: "proxy: '',"
#    FIND: "enable_vod: m3uAccount.enable_vod || false,"
#    ADD AFTER: "proxy: m3uAccount.proxy || '',"
#    FIND: placeholder="Enter server URL"
#    ADD AFTER: Proxy TextInput component
#
# 7. CONFIG CHANGES (apps/proxy/config.py + apps/proxy/ts_proxy/config_helper.py):
#    FIND: "MAX_RETRIES = 3"
#    REPLACE: "MAX_RETRIES = 2"
#    FIND: "class BaseConfig:"
#    ADD: Additional timeout and failover settings
#    FIND: "ConfigHelper.get('FAILOVER_GRACE_PERIOD', 20)"
#    REPLACE: "TSConfig.get_failover_grace_period()" (fixes property/method conflict)
#
# 8. FRONTEND SETTINGS (frontend/src/constants.js):
#    FIND: "export const PROXY_SETTINGS_OPTIONS"
#    FIND: "channel_init_grace_period:"
#    ADD AFTER: max_retries, url_switch_timeout, failover_grace_period
#
# ===============================================
# ENHANCEMENT DETAILS
# ===============================================
#
# 1. PROFILE FAILOVER SYSTEM
# ==========================
# IMPLEMENTATION: Advanced stream_manager.py approach (like 0.15.0-dev)
# 
# KEY CHANGES:
# - Enhanced _try_next_stream() with tried_combinations tracking
# - get_alternate_streams() returns all stream/profile combinations  
# - get_stream_info_for_profile() for specific profile URL generation
# - Intelligent failover: tries other profiles before switching streams
# - Runtime switching without client disconnection
# 
# FAILOVER LOGIC:
# 1. Current stream+profile fails
# 2. Try other profiles of same stream
# 3. Try profiles of next available streams
# 4. Track (stream_id, profile_id) combinations to avoid loops
# 5. Comprehensive error logging and recovery
#
# 2. BASIC AUTHENTICATION
# =======================
# IMPLEMENTATION: HTTP Basic Auth for M3U/EPG endpoints
# 
# KEY CHANGES:
# - get_basic_auth_user() function for credential validation
# - require_basic_auth() function for 401 responses
# - Integrated with Django user system
# - Backward compatible (optional authentication)
#
# 3. PROXY SUPPORT
# ================
# IMPLEMENTATION: Full-stack proxy support for M3U accounts
# 
# KEY CHANGES:
# - Database: proxy field in M3UAccount model
# - API: proxy field in serializer
# - Frontend: proxy input in M3U form
# - Migration: 0019_m3uaccount_proxy.py
#
# 4. CONFIGURABLE SETTINGS
# =========================
# IMPLEMENTATION: Reduced retries and configurable timeouts
# 
# KEY CHANGES:
# - MAX_RETRIES: 3 → 2
# - Added: url_switch_timeout, failover_grace_period
# - Frontend configuration options
# - Database-driven settings
#
# ===============================================
# AUTO-APPLICATION INSTRUCTIONS
# ===============================================
#
# TO APPLY TO NEW DISPATCHARR VERSION:
# 1. Run: patch -p1 < dispatcharr_enhancements.patch
# 2. If conflicts: Use search patterns above to manually locate and modify
# 3. Create migration: python manage.py makemigrations m3u
# 4. Apply migration: python manage.py migrate
# 5. Test: Basic auth, proxy field, profile failover
#
# VERIFICATION CHECKLIST:
# ✓ stream_manager.py has tried_combinations tracking
# ✓ stream_manager.py imports get_stream_info_for_profile
# ✓ url_utils.py get_alternate_streams() has profile_id parameter
# ✓ url_utils.py has get_stream_info_for_profile() function  
# ✓ output/views.py has basic auth functions
# ✓ M3U model has proxy field
# ✓ M3U serializer includes proxy in fields
# ✓ M3U form has proxy TextInput
# ✓ config.py has MAX_RETRIES = 2
# ✓ Migration 0019 exists and applied
#
# COMPATIBILITY: Tested with Dispatcharr 0.12.0-06, 0.15.0-dev, main
# SAFETY: All changes are backward compatible and optional
